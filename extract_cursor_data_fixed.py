#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CursorèŠå¤©æ•°æ®æå–è„šæœ¬ - ä¿®å¤ç‰ˆæœ¬
"""

import sqlite3
import json
import os
import sys
from pathlib import Path
import hashlib
from datetime import datetime
import re

class CursorDataExtractor:
    def __init__(self):
        self.cursor_path = self.get_cursor_path()
        print(f"ğŸ“ Cursorå­˜å‚¨è·¯å¾„: {self.cursor_path}")
        
    def get_cursor_path(self):
        """è·å–Cursorå­˜å‚¨è·¯å¾„"""
        home = Path.home()
        if os.name == 'nt':  # Windows
            return home / 'AppData' / 'Roaming' / 'Cursor'
        elif sys.platform == 'darwin':  # macOS
            return home / 'Library' / 'Application Support' / 'Cursor'
        else:  # Linux
            return home / '.config' / 'Cursor'
    
    def extract_chat_messages_from_global(self):
        """ä»å…¨å±€æ•°æ®åº“æå–èŠå¤©æ¶ˆæ¯"""
        global_db_path = self.cursor_path / 'User' / 'globalStorage' / 'state.vscdb'
        
        if not global_db_path.exists():
            print(f"âŒ å…¨å±€æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {global_db_path}")
            return []
        
        print(f"ğŸ“‚ å…¨å±€æ•°æ®åº“è·¯å¾„: {global_db_path}")
        print(f"ğŸ“Š æ•°æ®åº“æ–‡ä»¶å¤§å°: {global_db_path.stat().st_size / 1024 / 1024:.1f} MB")
        
        try:
            # è¿æ¥æ•°æ®åº“
            conn = sqlite3.connect(str(global_db_path))
            conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼
            cursor = conn.cursor()
            
            # æ£€æŸ¥è¡¨ç»“æ„
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            print(f"ğŸ“‹ æ‰¾åˆ°è¡¨: {', '.join(tables)}")
            
            if 'cursorDiskKV' not in tables:
                print("âŒ æœªæ‰¾åˆ°cursorDiskKVè¡¨")
                return []
            
            # æŸ¥è¯¢èŠå¤©æ°”æ³¡æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM cursorDiskKV WHERE key LIKE 'bubbleId:%'")
            bubble_count = cursor.fetchone()[0]
            print(f"ğŸ’¬ æ‰¾åˆ° {bubble_count} ä¸ªèŠå¤©æ°”æ³¡")
            
            if bubble_count == 0:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°èŠå¤©æ°”æ³¡æ•°æ®")
                return []
            
            # è·å–æ‰€æœ‰èŠå¤©æ°”æ³¡
            cursor.execute("SELECT key, value FROM cursorDiskKV WHERE key LIKE 'bubbleId:%'")
            bubbles = cursor.fetchall()
            
            conn.close()
            
            print(f"ğŸ“¦ æˆåŠŸè·å– {len(bubbles)} ä¸ªæ°”æ³¡")
            
            # åˆ†ç»„ä¸ºä¼šè¯
            sessions = self.group_into_sessions(bubbles)
            print(f"ğŸ“š æœ€ç»ˆæå–åˆ° {len(sessions)} ä¸ªä¼šè¯")
            
            return sessions
            
        except Exception as error:
            print(f"âŒ æ•°æ®åº“è®¿é—®å¤±è´¥: {error}")
            import traceback
            traceback.print_exc()
            return []
    
    def group_into_sessions(self, bubbles):
        """å°†æ°”æ³¡åˆ†ç»„ä¸ºä¼šè¯"""
        print(f"ğŸ”„ å¼€å§‹åˆ†ç»„ {len(bubbles)} ä¸ªæ°”æ³¡...")
        
        session_groups = {}
        parsed_count = 0
        error_count = 0
        
        for bubble in bubbles:
            try:
                key = bubble['key'] if isinstance(bubble, dict) else bubble[0]
                value = bubble['value'] if isinstance(bubble, dict) else bubble[1]
                
                # è§£æbubble keyæ ¼å¼: bubbleId:conversationId:bubbleId
                if not key.startswith('bubbleId:'):
                    continue
                
                parts = key.split(':')
                if len(parts) < 3:
                    continue
                
                conversation_id = parts[1]  # ä¸­é—´éƒ¨åˆ†æ˜¯ä¼šè¯ID
                bubble_id = parts[2]        # æœ€åéƒ¨åˆ†æ˜¯æ°”æ³¡ID
                
                if not value:
                    continue
                
                bubble_data = json.loads(value)
                parsed_count += 1
                
                if conversation_id not in session_groups:
                    session_groups[conversation_id] = []
                
                # æ·»åŠ è§£æå‡ºçš„IDä¿¡æ¯
                bubble_data['conversationId'] = conversation_id
                bubble_data['bubbleId'] = bubble_id
                
                session_groups[conversation_id].append(bubble_data)
                
            except Exception as error:
                error_count += 1
                if error_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    print(f"âš ï¸ è§£ææ°”æ³¡æ•°æ®å¤±è´¥: {error}")
        
        print(f"ğŸ“Š è§£æç»Ÿè®¡: æˆåŠŸ {parsed_count}, å¤±è´¥ {error_count}")
        print(f"ğŸ“ æ‰¾åˆ° {len(session_groups)} ä¸ªä¸åŒçš„ä¼šè¯")
        
        sessions = []
        for conversation_id, session_bubbles in session_groups.items():
            if not session_bubbles:
                continue
            
            # æŒ‰æ—¶é—´æ’åºï¼ˆå¦‚æœæœ‰æ—¶é—´æˆ³ä¿¡æ¯ï¼‰
            session_bubbles.sort(key=lambda x: x.get('cTime', x.get('timestamp', 0)))
            
            messages = []
            session_info = {
                'sessionId': conversation_id,
                'timestamp': None,
                'workspaceInfo': None
            }
            
            for bubble in session_bubbles:
                # æå–æ¶ˆæ¯å†…å®¹
                message_content = ""
                message_type = "unknown"
                
                # æ£€æŸ¥bubbleçš„ç±»å‹
                bubble_type = bubble.get('type', 0)
                
                if bubble_type == 1:  # ç”¨æˆ·æ¶ˆæ¯
                    message_type = "user"
                    message_content = bubble.get('text', '')
                elif bubble_type == 2:  # AIå›å¤
                    message_type = "assistant"
                    message_content = bubble.get('text', '')
                    
                    # å°è¯•ä»richTextè·å–æ›´å¥½çš„æ ¼å¼
                    rich_text = bubble.get('richText')
                    if rich_text and isinstance(rich_text, str) and len(rich_text) > len(message_content):
                        message_content = rich_text
                
                # å¦‚æœæœ‰æœ‰æ•ˆå†…å®¹ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
                if message_content and message_content.strip():
                    messages.append({
                        'role': message_type,
                        'content': message_content.strip(),
                        'timestamp': bubble.get('cTime', bubble.get('timestamp'))
                    })
                
                # å°è¯•è·å–ä¼šè¯çš„æ—¶é—´æˆ³
                if not session_info['timestamp']:
                    session_info['timestamp'] = bubble.get('cTime', bubble.get('timestamp'))
            
            # åªä¿ç•™æœ‰æœ‰æ•ˆæ¶ˆæ¯çš„ä¼šè¯
            if messages:
                sessions.append({
                    'sessionId': conversation_id,
                    'messages': messages,
                    'timestamp': session_info['timestamp'] or datetime.now().isoformat()
                })
        
        print(f"âœ… æˆåŠŸåˆ›å»º {len(sessions)} ä¸ªæœ‰æ•ˆä¼šè¯")
        
        # æŒ‰æ¶ˆæ¯æ•°é‡æ’åºï¼Œæ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
        sessions.sort(key=lambda x: len(x['messages']), reverse=True)
        
        if sessions:
            print(f"ğŸ“Š ä¼šè¯ç»Ÿè®¡:")
            print(f"  æœ€å¤§ä¼šè¯: {len(sessions[0]['messages'])} æ¡æ¶ˆæ¯")
            print(f"  å¹³å‡ä¼šè¯: {sum(len(s['messages']) for s in sessions) // len(sessions)} æ¡æ¶ˆæ¯")
            total_messages = sum(len(s['messages']) for s in sessions)
            print(f"  æ€»æ¶ˆæ¯æ•°: {total_messages}")
        
        return sessions
    
    def extract_workspace_projects(self):
        """æå–å·¥ä½œåŒºé¡¹ç›®ä¿¡æ¯"""
        workspace_storage_path = self.cursor_path / 'User' / 'workspaceStorage'
        
        if not workspace_storage_path.exists():
            print(f"âŒ å·¥ä½œåŒºå­˜å‚¨è·¯å¾„ä¸å­˜åœ¨: {workspace_storage_path}")
            return {}
        
        projects = {}
        workspace_dirs = [d for d in workspace_storage_path.iterdir() if d.is_dir()]
        print(f"ğŸ” æ‰¾åˆ° {len(workspace_dirs)} ä¸ªå·¥ä½œåŒºç›®å½•")
        
        for workspace_dir in workspace_dirs[:20]:  # é™åˆ¶å¤„ç†å‰20ä¸ª
            try:
                state_db_path = workspace_dir / 'state.vscdb'
                if not state_db_path.exists():
                    continue
                
                project_info = self.extract_project_info_from_workspace(str(state_db_path))
                if project_info:
                    workspace_id = workspace_dir.name
                    projects[workspace_id] = project_info
                    
            except Exception as error:
                continue  # å¿½ç•¥å•ä¸ªå·¥ä½œåŒºçš„é”™è¯¯
        
        print(f"ğŸ“ æˆåŠŸæå– {len(projects)} ä¸ªé¡¹ç›®ä¿¡æ¯")
        return projects
    
    def extract_project_info_from_workspace(self, db_path):
        """ä»å·¥ä½œåŒºæ•°æ®åº“æå–é¡¹ç›®ä¿¡æ¯"""
        try:
            conn = sqlite3.connect(db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            project_info = {
                'name': 'Unknown Project',
                'rootPath': None,
                'fileCount': 0
            }
            
            # å°è¯•ä»ä¸åŒçš„keyè·å–é¡¹ç›®ä¿¡æ¯
            keys_to_check = [
                'history.entries',
                'debug.selectedroot',
                'memento/workbench.editors.files.textFileEditor'
            ]
            
            for key in keys_to_check:
                cursor.execute("SELECT value FROM cursorDiskKV WHERE key = ?", (key,))
                result = cursor.fetchone()
                if result and result[0]:
                    try:
                        data = json.loads(result[0])
                        path_info = self.extract_path_from_data(data)
                        if path_info:
                            project_info['rootPath'] = path_info
                            project_info['name'] = self.extract_project_name_from_path(path_info)
                            break
                    except:
                        continue
            
            conn.close()
            return project_info if project_info['rootPath'] else None
            
        except Exception as error:
            return None
    
    def extract_path_from_data(self, data):
        """ä»æ•°æ®ä¸­æå–è·¯å¾„ä¿¡æ¯"""
        if isinstance(data, list) and data:
            # history.entriesæ ¼å¼
            first_entry = data[0]
            if isinstance(first_entry, dict) and 'resource' in first_entry:
                resource = first_entry['resource']
                if isinstance(resource, dict) and 'path' in resource:
                    return self.extract_project_path(resource['path'])
        elif isinstance(data, str):
            # ç›´æ¥è·¯å¾„å­—ç¬¦ä¸²
            return self.extract_project_path(data)
        elif isinstance(data, dict):
            # å…¶ä»–æ ¼å¼ï¼Œé€’å½’æŸ¥æ‰¾è·¯å¾„
            for value in data.values():
                if isinstance(value, str) and ('file://' in value or '\\' in value or '/' in value):
                    return self.extract_project_path(value)
        
        return None
    
    def extract_project_path(self, path_str):
        """ä»è·¯å¾„å­—ç¬¦ä¸²æå–é¡¹ç›®è·¯å¾„"""
        if not path_str:
            return None
        
        # å¤„ç†file://åè®®
        if path_str.startswith('file:///'):
            path_str = path_str[8:]  # ç§»é™¤ file:///
            if os.name == 'nt':  # Windows
                path_str = path_str.replace('/', '\\')
        
        # URLè§£ç 
        try:
            import urllib.parse
            path_str = urllib.parse.unquote(path_str)
        except:
            pass
        
        return path_str
    
    def extract_project_name_from_path(self, path_str):
        """ä»è·¯å¾„æå–é¡¹ç›®åç§°"""
        if not path_str:
            return 'Unknown Project'
        
        try:
            path_obj = Path(path_str)
            return path_obj.name
        except:
            # æ‰‹åŠ¨å¤„ç†
            path_str = path_str.replace('\\', '/').rstrip('/')
            parts = path_str.split('/')
            return parts[-1] if parts else 'Unknown Project'
    
    def match_session_to_real_project(self, session, projects_array):
        """å°†ä¼šè¯åŒ¹é…åˆ°çœŸå®é¡¹ç›®"""
        if not projects_array:
            return None
        
        session_content = ' '.join([msg.get('content', '') for msg in session.get('messages', [])]).lower()
        
        best_match = None
        best_score = 0
        
        for project in projects_array:
            score = 0
            project_name = project.get('name', '').lower()
            project_path = project.get('rootPath', '').lower()
            
            # é¡¹ç›®ååŒ¹é…
            if project_name and project_name in session_content:
                score += 10
            
            # è·¯å¾„éƒ¨åˆ†åŒ¹é…
            if project_path:
                path_parts = project_path.replace('\\', '/').split('/')
                for part in path_parts:
                    if part and len(part) > 2 and part in session_content:
                        score += 5
            
            if score > best_score:
                best_score = score
                best_match = project
        
        # åªæœ‰å½“åŒ¹é…åˆ†æ•°è¶³å¤Ÿé«˜æ—¶æ‰è¿”å›åŒ¹é…ç»“æœ
        if best_match and best_score >= 5:
            return best_match
        
        return None
    
    def infer_project_from_path_hints(self, messages, session_index):
        """ä»æ¶ˆæ¯å†…å®¹ä¸­çš„è·¯å¾„æç¤ºæ¨æ–­é¡¹ç›®ä¿¡æ¯"""
        all_text = ' '.join([msg.get('content', '') for msg in messages])
        
        # å¤šå±‚æ¬¡è·¯å¾„æ¨¡å¼åŒ¹é…
        path_patterns = [
            # å®Œæ•´çš„ç»å¯¹è·¯å¾„
            r'[A-Za-z]:\\[^\s<>:"|?*\n\r]+(?:\\[^\s<>:"|?*\n\r]+)+',  # Windowså®Œæ•´è·¯å¾„
            r'/(?:[a-zA-Z0-9_.-]+/)+[a-zA-Z0-9_.-]*',  # Unixå®Œæ•´è·¯å¾„
            
            # é¡¹ç›®ç›¸å…³çš„æ–‡ä»¶è·¯å¾„æ¨¡å¼
            r'(?:src|app|components|pages|utils|lib|modules|services|api|public|assets)(?:/|\\)[^\s<>:"|?*\n\r]+',  # é¡¹ç›®ç»“æ„è·¯å¾„
            r'[a-zA-Z0-9_.-]+\.[a-zA-Z]{2,4}(?:\s|$)',  # æ–‡ä»¶å
            
            # ç›®å½•åæ¨¡å¼
            r'[a-zA-Z0-9_-]+(?:-[a-zA-Z0-9_-]+)*(?:ç›®å½•|directory|folder|é¡¹ç›®|project)',  # ç›®å½•æè¿°
        ]
        
        found_paths = []
        project_indicators = []
        
        for pattern in path_patterns:
            matches = re.findall(pattern, all_text, re.IGNORECASE)
            for match in matches:
                cleaned_match = match.strip()
                if self.is_likely_project_path(cleaned_match):
                    found_paths.append(cleaned_match)
                elif self.is_project_indicator(cleaned_match):
                    project_indicators.append(cleaned_match)
        
        # å°è¯•ä»å®Œæ•´è·¯å¾„æå–é¡¹ç›®ä¿¡æ¯
        if found_paths:
            common_path = self.find_common_project_path(found_paths)
            if common_path:
                project_name = self.extract_project_name_from_path(common_path)
                return {
                    'name': project_name,
                    'rootPath': common_path,
                    'fileCount': len(messages) + 5
                }
        
        # å¦‚æœæ²¡æœ‰å®Œæ•´è·¯å¾„ï¼Œå°è¯•ä»é¡¹ç›®æŒ‡ç¤ºå™¨æ¨æ–­
        if project_indicators:
            project_name = self.infer_project_name_from_indicators(project_indicators)
            if project_name and project_name != 'Unknown':
                return {
                    'name': project_name,
                    'rootPath': f'C:\\Projects\\{project_name}',
                    'fileCount': len(messages) + 5
                }
        
        # æœ€åå°è¯•ä»æ¶ˆæ¯å†…å®¹æ¨æ–­é¡¹ç›®ç±»å‹
        inferred_name = self.infer_from_content_keywords(all_text)
        if inferred_name:
            return {
                'name': inferred_name,
                'rootPath': f'C:\\Projects\\{inferred_name}',
                'fileCount': len(messages) + 5
            }
        
        # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é€šç”¨åˆ†ç±»
        return {
            'name': f'æœªåˆ†ç±»é¡¹ç›®_{session_index + 1}',
            'rootPath': f'C:\\Projects\\æœªåˆ†ç±»é¡¹ç›®_{session_index + 1}',
            'fileCount': len(messages) + 5
        }
    
    def is_likely_project_path(self, path):
        """åˆ¤æ–­è·¯å¾„æ˜¯å¦å¯èƒ½æ˜¯é¡¹ç›®è·¯å¾„"""
        if not path or len(path) < 3:
            return False
        
        # æ’é™¤ç³»ç»Ÿè·¯å¾„å’Œä¸´æ—¶è·¯å¾„
        exclude_patterns = [
            r'C:\\Windows',
            r'C:\\Program Files',
            r'C:\\Users\\[^\\]+\\AppData',
            r'C:\\temp',
            r'/tmp',
            r'/var',
            r'/usr',
            r'/bin',
            r'/etc'
        ]
        
        for pattern in exclude_patterns:
            if re.match(pattern, path, re.IGNORECASE):
                return False
        
        # åŒ…å«å¸¸è§é¡¹ç›®å…³é”®è¯çš„è·¯å¾„æ›´å¯èƒ½æ˜¯é¡¹ç›®è·¯å¾„
        project_keywords = ['project', 'workspace', 'repo', 'code', 'dev', 'src', 'app', 'web', 'api', 'frontend', 'backend']
        path_lower = path.lower()
        for keyword in project_keywords:
            if keyword in path_lower:
                return True
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´è·¯å¾„
        if '\\' in path or '/' in path:
            depth = len(path.replace('/', '\\').split('\\'))
            return 2 <= depth <= 8
        
        return False
    
    def is_project_indicator(self, text):
        """åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜¯é¡¹ç›®æŒ‡ç¤ºå™¨"""
        if not text or len(text) < 2:
            return False
        
        # é¡¹ç›®ç›¸å…³çš„å…³é”®è¯
        indicators = [
            'cursor-view', 'cursor-web', 'react', 'vue', 'angular', 'node', 'express',
            'webpack', 'vite', 'next', 'nuxt', 'gatsby', 'svelte', 'typescript',
            'javascript', 'python', 'django', 'flask', 'fastapi', 'spring', 'maven',
            'gradle', 'docker', 'kubernetes', 'nginx', 'apache', 'mysql', 'postgresql',
            'mongodb', 'redis', 'elasticsearch', 'rabbitmq', 'kafka'
        ]
        
        text_lower = text.lower()
        return any(indicator in text_lower for indicator in indicators)
    
    def infer_project_name_from_indicators(self, indicators):
        """ä»é¡¹ç›®æŒ‡ç¤ºå™¨æ¨æ–­é¡¹ç›®åç§°"""
        if not indicators:
            return None
        
        # ç»Ÿè®¡æŒ‡ç¤ºå™¨å‡ºç°é¢‘ç‡
        indicator_counts = {}
        for indicator in indicators:
            clean_indicator = re.sub(r'[^a-zA-Z0-9_-]', '', indicator.lower())
            if len(clean_indicator) > 2:
                indicator_counts[clean_indicator] = indicator_counts.get(clean_indicator, 0) + 1
        
        if indicator_counts:
            # è¿”å›å‡ºç°é¢‘ç‡æœ€é«˜çš„æŒ‡ç¤ºå™¨
            return max(indicator_counts.items(), key=lambda x: x[1])[0]
        
        return None
    
    def infer_from_content_keywords(self, content):
        """ä»å†…å®¹å…³é”®è¯æ¨æ–­é¡¹ç›®ç±»å‹"""
        if not content:
            return None
        
        content_lower = content.lower()
        
        # æŠ€æœ¯æ ˆå…³é”®è¯æ˜ å°„
        tech_keywords = {
            'webå¼€å‘': ['html', 'css', 'javascript', 'web', 'browser', 'æµè§ˆå™¨', 'ç½‘é¡µ'],
            'reacté¡¹ç›®': ['react', 'jsx', 'component', 'hook', 'state'],
            'vueé¡¹ç›®': ['vue', 'vuex', 'router', 'template'],
            'nodeé¡¹ç›®': ['node', 'npm', 'express', 'server', 'æœåŠ¡å™¨'],
            'pythoné¡¹ç›®': ['python', 'pip', 'django', 'flask', 'fastapi'],
            'apié¡¹ç›®': ['api', 'rest', 'graphql', 'endpoint', 'æ¥å£'],
            'æ•°æ®åº“é¡¹ç›®': ['database', 'sql', 'mysql', 'postgresql', 'mongodb', 'æ•°æ®åº“'],
            'ç§»åŠ¨å¼€å‘': ['mobile', 'android', 'ios', 'react-native', 'flutter', 'ç§»åŠ¨'],
            'æ¡Œé¢åº”ç”¨': ['desktop', 'electron', 'tauri', 'qt', 'æ¡Œé¢'],
            'æ¸¸æˆå¼€å‘': ['game', 'unity', 'unreal', 'godot', 'æ¸¸æˆ'],
            'æœºå™¨å­¦ä¹ ': ['ml', 'ai', 'tensorflow', 'pytorch', 'sklearn', 'æœºå™¨å­¦ä¹ ', 'äººå·¥æ™ºèƒ½']
        }
        
        # ç»Ÿè®¡æ¯ä¸ªæŠ€æœ¯æ ˆçš„å…³é”®è¯å‡ºç°æ¬¡æ•°
        tech_scores = {}
        for tech, keywords in tech_keywords.items():
            score = sum(1 for keyword in keywords if keyword in content_lower)
            if score > 0:
                tech_scores[tech] = score
        
        if tech_scores:
            # è¿”å›å¾—åˆ†æœ€é«˜çš„æŠ€æœ¯æ ˆ
            return max(tech_scores.items(), key=lambda x: x[1])[0]
        
        return None
    
    def find_common_project_path(self, paths):
        """ä»è·¯å¾„åˆ—è¡¨ä¸­æ‰¾åˆ°æœ€å¯èƒ½çš„é¡¹ç›®æ ¹è·¯å¾„"""
        if not paths:
            return None
        
        # ç»Ÿè®¡å¯èƒ½çš„é¡¹ç›®æ ¹è·¯å¾„
        project_roots = {}
        
        for path in paths:
            # æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦
            normalized_path = path.replace('/', '\\')
            parts = normalized_path.split('\\')
            
            # å°è¯•ä¸åŒçš„é¡¹ç›®æ ¹è·¯å¾„æ·±åº¦
            for depth in range(2, min(len(parts), 6)):
                potential_root = '\\'.join(parts[:depth])
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„é¡¹ç›®æ ¹è·¯å¾„
                if self.is_reasonable_project_root(potential_root):
                    project_roots[potential_root] = project_roots.get(potential_root, 0) + 1
        
        if project_roots:
            # è¿”å›å‡ºç°é¢‘ç‡æœ€é«˜ä¸”æœ€åˆç†çš„é¡¹ç›®æ ¹è·¯å¾„
            return max(project_roots.items(), key=lambda x: x[1])[0]
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆç†çš„é¡¹ç›®æ ¹ï¼Œè¿”å›æœ€çŸ­çš„è·¯å¾„
        return min(paths, key=len) if paths else None
    
    def is_reasonable_project_root(self, path):
        """åˆ¤æ–­æ˜¯å¦æ˜¯åˆç†çš„é¡¹ç›®æ ¹è·¯å¾„"""
        if not path or len(path) < 3:
            return False
        
        # è·¯å¾„åº”è¯¥æœ‰åˆç†çš„æ·±åº¦
        parts = path.split('\\')
        if len(parts) < 2 or len(parts) > 5:
            return False
        
        # æœ€åä¸€çº§ç›®å½•ååº”è¯¥åƒé¡¹ç›®å
        last_part = parts[-1].lower()
        
        # æ’é™¤æ˜æ˜¾çš„ç³»ç»Ÿç›®å½•
        system_dirs = ['windows', 'program files', 'appdata', 'temp', 'system32']
        if any(sys_dir in last_part for sys_dir in system_dirs):
            return False
        
        # é¡¹ç›®ç›®å½•é€šå¸¸ä¸ä¼šæ˜¯å•ä¸ªå­—ç¬¦
        if len(last_part) <= 1:
            return False
        
        return True
    
    def run_extraction(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®æå–æµç¨‹"""
        print("ğŸš€ å¼€å§‹Cursoræ•°æ®æå–...\n")
        
        try:
            # æå–èŠå¤©ä¼šè¯
            sessions = self.extract_chat_messages_from_global()
            if not sessions:
                print("âŒ æœªèƒ½æå–åˆ°èŠå¤©ä¼šè¯")
                return []
            
            # æå–é¡¹ç›®ä¿¡æ¯
            print("\nğŸ” æå–å·¥ä½œåŒºé¡¹ç›®ä¿¡æ¯...")
            projects = self.extract_workspace_projects()
            projects_array = list(projects.values())
            
            # å¤„ç†æ¯ä¸ªä¼šè¯
            print(f"\nğŸ“ å¤„ç† {len(sessions)} ä¸ªä¼šè¯...")
            processed_chats = []
            
            for i, session in enumerate(sessions):
                # å°è¯•åŒ¹é…åˆ°çœŸå®é¡¹ç›®
                project_info = self.match_session_to_real_project(session, projects_array)
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°çœŸå®é¡¹ç›®ï¼Œä½¿ç”¨è·¯å¾„æ¨æ–­
                if not project_info:
                    project_info = self.infer_project_from_path_hints(session['messages'], i)
                
                chat_data = {
                    'sessionId': session['sessionId'],
                    'project': project_info,
                    'messages': session['messages'],
                    'timestamp': session['timestamp'],
                    'date': session['timestamp']
                }
                
                processed_chats.append(chat_data)
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 50 == 0 or i == len(sessions) - 1:
                    print(f"  å¤„ç†è¿›åº¦: {i + 1}/{len(sessions)}")
            
            # æŒ‰æ—¶é—´æ’åº
            processed_chats.sort(key=lambda x: x['timestamp'], reverse=True)
            
            print(f"\nâœ… æˆåŠŸå¤„ç† {len(processed_chats)} ä¸ªèŠå¤©ä¼šè¯")
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            output_file = 'test-chat-data.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(processed_chats, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° {output_file}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {Path(output_file).stat().st_size / 1024 / 1024:.1f} MB")
            
            return processed_chats
            
        except Exception as error:
            print(f"âŒ æå–å¤±è´¥: {error}")
            import traceback
            traceback.print_exc()
            return []

def main():
    extractor = CursorDataExtractor()
    result = extractor.run_extraction()
    
    if result:
        print(f"\nğŸ‰ æå–å®Œæˆï¼å…± {len(result)} ä¸ªä¼šè¯")
        
        # æ˜¾ç¤ºé¡¹ç›®ç»Ÿè®¡
        project_stats = {}
        for chat in result:
            project_name = chat['project']['name']
            project_stats[project_name] = project_stats.get(project_name, 0) + 1
        
        print("\nğŸ“Š é¡¹ç›®åˆ†å¸ƒ:")
        for project, count in sorted(project_stats.items(), key=lambda x: x[1], reverse=True)[:15]:
            print(f"  {project}: {count} ä¸ªä¼šè¯")
        
        if len(project_stats) > 15:
            others = sum(list(project_stats.values())[15:])
            print(f"  ... å…¶ä»–: {others} ä¸ªä¼šè¯")
    else:
        print("\nâŒ æå–å¤±è´¥")

if __name__ == "__main__":
    main()